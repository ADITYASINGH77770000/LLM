{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3eb1c5-78b5-4f79-965e-57d158956ee9",
   "metadata": {},
   "source": [
    "# Ollama 3.2 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d24bcda-69a4-4023-9961-e89d750382f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales is a crucial function in any organization, and its applications extend far beyond just generating revenue. Here are some common business applications of sales:\n",
      "\n",
      "1. **Revenue Generation**: The most obvious application of sales is to generate revenue for an organization by selling products or services.\n",
      "2. **Market Research**: Sales teams play a vital role in gathering market intelligence, understanding customer needs, and identifying new business opportunities.\n",
      "3. **Product Development**: Sales data can inform product development, helping companies create products that meet specific customer needs and preferences.\n",
      "4. **Customer Acquisition and Retention**: Sales efforts focus on acquiring new customers and retaining existing ones, which is essential for long-term business growth.\n",
      "5. **Competitive Intelligence**: Sales teams gather information about competitors' strategies, pricing, and offerings, enabling organizations to stay competitive in the market.\n",
      "6. **Market Expansion**: Successful sales teams can help companies expand into new markets, geographies, or customer segments.\n",
      "7. **Pricing Strategy Development**: Sales data can inform pricing strategy, ensuring that products are priced competitively while maximizing revenue potential.\n",
      "8. **Sales Enablement**: Sales teams often work closely with other departments, such as marketing and product development, to ensure a cohesive sales strategy that supports business objectives.\n",
      "9. **Customer Feedback Collection**: Sales interactions provide valuable feedback from customers, which can be used to improve products, services, or overall customer experience.\n",
      "10. **Business Planning and Budgeting**: Sales performance data informs business planning and budgeting decisions, ensuring that sales targets are aligned with organizational goals.\n",
      "\n",
      "Some specific examples of businesses that rely heavily on sales include:\n",
      "\n",
      "* E-commerce companies\n",
      "* Software-as-a-Service (SaaS) providers\n",
      "* Financial institutions\n",
      "* Healthcare organizations\n",
      "* Manufacturing companies\n",
      "* Retailers\n",
      "\n",
      "In each of these industries, sales plays a critical role in driving revenue growth, customer acquisition, and market success.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json  # Correct import for JSON parsing\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"  # Ensure this matches the installed model name\n",
    "\n",
    "# Payload\n",
    "messages = [{\"role\": \"user\", \"content\": \"Describe some of the business applications for sales\"}]\n",
    "payload = {\"model\": MODEL, \"messages\": messages}\n",
    "\n",
    "# API Request\n",
    "try:\n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS, stream=True)  # Enable streaming\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # Read and process the streamed response line by line\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    response_json = json.loads(line.decode(\"utf-8\"))  # Proper JSON parsing\n",
    "                    if \"message\" in response_json:\n",
    "                        print(response_json[\"message\"][\"content\"], end=\"\")  # Print response progressively\n",
    "            print()  # Print newline at the end\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON response.\")\n",
    "            print(\"Raw Response:\", response.text)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bb489-464e-42c4-b37f-e3209bed8eb4",
   "metadata": {},
   "source": [
    "# Web Scrapping Using Ollama 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff96a962-caa6-4fc4-84e6-d8d581644ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying which category an object belongs to.\n",
      "\n",
      "Applications: Spam detection, image recognition.\n",
      "Algorithms:\n",
      "Gradient boosting,\n",
      "            nearest neighbors,\n",
      "            random forest,\n",
      "            logistic regression,\n",
      "            and more...\n",
      "\n",
      "Predicting a continuous-valued attribute associated with an object.\n",
      "\n",
      "Applications: Drug response, stock prices.\n",
      "Algorithms:\n",
      "Gradient boosting,\n",
      "            nearest neighbors,\n",
      "            random forest,\n",
      "            ridge,\n",
      "            and more...\n",
      "\n",
      "Automatic grouping of similar objects into sets.\n",
      "\n",
      "Applications: Customer segmentation, grouping experiment outcomes.\n",
      "Algorithms:\n",
      "k-Means,\n",
      "            HDBSCAN,\n",
      "            hierarchical clustering,\n",
      "            and more...\n",
      "\n",
      "Reducing the number of random variables to consider.\n",
      "\n",
      "Applications: Visualization, increased efficiency.\n",
      "Algorithms:\n",
      "PCA,\n",
      "            feature selection,\n",
      "            non-negative matrix factorization,\n",
      "            and more...\n",
      "\n",
      "Comparing, validating and choosing parameters and models.\n",
      "\n",
      "Applications: Improved accuracy via parameter tuning.\n",
      "Algorithms:\n",
      "Grid search,\n",
      "            cross validation,\n",
      "            metrics,\n",
      "            and more...\n",
      "\n",
      "Feature extraction and normalization.\n",
      "\n",
      "Applications: Transforming input data such as text for use with machine learning algorithms.\n",
      "Algorithms:\n",
      "Preprocessing,\n",
      "            feature extraction,\n",
      "            and more...\n",
      "\n",
      "\n",
      "Help us, donate!\n",
      "Cite us!\n",
      "\n",
      "\n",
      "More testimonials...\n",
      "\n",
      "\n",
      "          scikit-learn development and maintenance are financially supported by\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup # Library to parse HTML\n",
    "\n",
    "# URL of the web page you want to scrape\n",
    "URL = \"https://scikit-learn.org/stable/\" # Replace with the actual URL\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "try:\n",
    "    response = requests.get(URL)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # Parse the HTML content of the page using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "             # Extract specific content (for example, all paragraphs)\n",
    "            paragraphs = soup.find_all('p') # Find all <p> tags (can be any HTML element)\n",
    "\n",
    "             # Print the content of each paragraph\n",
    "            for para in paragraphs:\n",
    "                print(para.get_text()) # Extract and print text from each paragraph\n",
    "\n",
    "        except Exception as e :\n",
    "            print(\"An error occurred while parsing the content.\")\n",
    "            print(f\"Error details:{e}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        \n",
    "except requests.exception.RequestsException as e:\n",
    "    print(f\"AN error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8eacc-3d2b-48ca-b4e0-b8a9f4babbba",
   "metadata": {},
   "source": [
    "# Agentic 1 (Ollama Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3adec48-e040-46b3-b82b-fc0922912d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "load_dotenv(override=True)\n",
    "\n",
    "MODEL = 'llama3'  # Ollama model name (Change this to the model you have downloaded e.g., mistral)\n",
    "API_ENDPOINT = \"http://localhost:11434/generate\" # Ollama default api endpoint\n",
    "\n",
    "# Define headers to mimic a browser request\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# A class to represent a Webpage\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        try:\n",
    "             response = requests.get(url, headers=headers, timeout=10)\n",
    "             response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Error fetching URL {url}: {e}\")\n",
    "            self.body = \"\"\n",
    "            self.title = \"Error fetching page\"\n",
    "            self.text = \"Error fetching page\"\n",
    "            self.links = []\n",
    "            return\n",
    "        \n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "# System prompt for generating the brochure\n",
    "system_prompt = (\n",
    "    \"You are an assistant that analyzes the contents of several relevant pages from a company website \"\n",
    "    \"and creates a short brochure about the company for prospective customers, investors and recruits. \"\n",
    "    \"Respond in markdown. Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    ")\n",
    "\n",
    "# Generate user prompt for extracting relevant information\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL and type of link in JSON format. \"\n",
    "    user_prompt += \"The valid types are: 'company-related' or 'career-related'. \"\n",
    "    user_prompt += \"Do not include Terms of Service, Privacy, email links. Respond in the JSON format:\"\n",
    "    user_prompt += \"`[{\\\"url\\\": \\\"https://...\\\", \\\"type\\\": \\\"company-related\\\"},{\\\"url\\\": \\\"https://...\\\", \\\"type\\\": \\\"career-related\\\"}]`\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "    ]\n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": \"\\n\".join(message[\"content\"] for message in messages),\n",
    "        \"stream\": False # set to false to avoid handling a stream of responses\n",
    "      }\n",
    "    response = None # Initialize response variable\n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=data, timeout=20) # increased the timeout to 20 seconds\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        json_response = response.json()\n",
    "        if 'response' in json_response:\n",
    "             result = json_response[\"response\"]\n",
    "             # Remove backticks and code block markers from the generated JSON\n",
    "             result = re.sub(r'```(json)?', '', result).strip()\n",
    "             return json.loads(result)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "         logging.error(f\"Request error: {e}\")\n",
    "    except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "        logging.error(f\"JSON Decode Error: {e}. Response Text: {response.text if response else 'No response received'}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    if response:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "    else:\n",
    "         print(f\"Error: No response received\")\n",
    "    return {\"links\": []}\n",
    "\n",
    "\n",
    "# Function to get all details and content of the website\n",
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()  # Use Website(url) here\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links:\n",
    "       try:\n",
    "           if isinstance(link, dict) and \"url\" in link:\n",
    "             result += f\"\\n\\n{link.get('type', 'unknown-type')}\\n\"\n",
    "             result += Website(link[\"url\"]).get_contents() # use Website() here\n",
    "           else:\n",
    "              logging.warning(f\"Invalid link format: {link}\")\n",
    "       except Exception as e:\n",
    "            logging.error(f\"Error processing link {link}: {e}\")\n",
    "    return result\n",
    "\n",
    "# User prompt to build the brochure\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000]  # Truncate if more than 5,000 characters\n",
    "    return user_prompt\n",
    "\n",
    "# Final function to create the brochure\n",
    "def create_brochure(company_name, url):\n",
    "     messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ]\n",
    "     data = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": \"\\n\".join(message[\"content\"] for message in messages),\n",
    "        \"stream\": True # Set to true to receive a stream of responses\n",
    "      }\n",
    "     response = None # Initialize response variable\n",
    "     try:\n",
    "         response = requests.post(API_ENDPOINT, headers=headers, json=data, stream=True, timeout=20)\n",
    "         response.raise_for_status()\n",
    "         full_response = \"\"\n",
    "         for line in response.iter_lines():\n",
    "                if line:\n",
    "                   json_line = json.loads(line)\n",
    "                   if 'response' in json_line:\n",
    "                         full_response += json_line[\"response\"]\n",
    "                         # Print the response as it streams in\n",
    "         print(full_response)\n",
    "         return\n",
    "     except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Request error: {e}\")\n",
    "     except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "        logging.error(f\"JSON Decode Error: {e}. Response Text: {response.text if response else 'No response received'}\")\n",
    "     except Exception as e:\n",
    "         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "     if response:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "     else:\n",
    "         print(f\"Error: No response received\")\n",
    "     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3cfb7ed-1a01-4581-adbc-b4acf5e7a1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 12:06:06,470 - ERROR - Request error: 404 Client Error: Not Found for url: http://localhost:11434/generate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No response received\n",
      "Found links: {'links': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 12:06:08,525 - ERROR - Request error: 404 Client Error: Not Found for url: http://localhost:11434/generate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No response received\n"
     ]
    }
   ],
   "source": [
    "create_brochure(\"ScikitLearn\", \"https://scikit-learn.org/stable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494f57b-0791-44cb-a57b-7c160bb8eebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
